\section{Data Gathering}

Considering the context (US elections) it is imperative to have users' data divided between left and right-leaning, so a group of \textit{super-users} was selected using various sources. 
\textit{Super-users} are defined as follows:

\begin{itemize}
    \item Influencers: people whose notoriety is platform-built, without a background in institutions of entertainment;
    \item Politicians;
    \item Newspapers or news sites (i.e., The Washington Post).
\end{itemize}

The complete followers list, with relative sources (missing if selected arbitrarily by the authors), is as follows:

\begin{itemize}
    \item Left-Wing: 
        \begin{itemize}
            \item @aocinthehouse \cite{wikiDem,yougovDem}
            \item @bernie \cite{wikiDem,yougovDem}
            \item @chrisdmowrey \cite{foxRight}
            \item @cnn \cite{biasCheck1,biasCheck2}
            \item @democracynow.org [unofficial]
            \item @genzforchange \cite{climateCulture}
            \item @ginadivittorio \cite{NYTpayInfluencers}
            \item @harryjsisson \cite{foxRight}
            \item @huffpost \cite{biasCheck1,biasCheck2}
            \item @msnbc \cite{biasCheck1,biasCheck2}
            \item @newyorker \cite{biasCheck1,biasCheck2}
            \item @nytimes \cite{biasCheck1,biasCheck2}
            \item @repbowman \cite{politico}
            \item @rynnstar \cite{https://doi.org/10.1002/poi3.287}
            \item @teamkennedy2024 \cite{wikiDem,yougovDem}
            \item @thedailybeast \cite{biasCheck1,biasCheck2}
            \item @underthedesknews \cite{foxRight}
            \item @vox \cite{biasCheck1,biasCheck2}
            \item @washingtonpost \cite{biasCheck1,biasCheck2}
        \end{itemize}
    \item Right-Wing:
        \begin{itemize}
            \item @alynicolee1126 \cite{mozilla}
            \item @babylonbee \cite{foxProFreeSpech}
            \item @clarksonlawson \cite{foxRight}
            \item @dailymail \cite{biasCheck1,biasCheck2}
            \item @dailywire \cite{biasCheck1,biasCheck2}
            \item @itsthemandrew \cite{mozilla}
            \item @notvictornieves \cite{foxRight}
            \item @real.benshapiro \cite{doi:10.1177/20563051231177938}
            \item @studentsforlife \cite{foxProFreeSpech}
            \item @theisabelbrown \cite{mozilla}
            \item @thesun \cite{biasCheck1,biasCheck2}
        \end{itemize}
\end{itemize}

Due to time and computational constraints, only five super-users had been selected from each group: \textit{@alynicolee1126, @babylonbee, @real.benshapiro, @clarksonlawson, @notvictornieves} for right-leaning, and \textit{@thedailybeast, @huffpost, @aocinthehouse, @repbowman, @newyorker} for left-leaning super-users. \\
All data has been gathered using TikTok's official APIs (\url{https://developers.tiktok.com/doc/overview/})

\subsection{TikTok's APIs}

TikTok's APIs requires prior authentication using a Secret Key and a Client ID, both of which can be obtained by making a personal request to the platform's staff. 
Then, each call to the API must be authenticated with a Bearer token, previously obtained through the appropriate authentication endpoint. Each one has its own query string and body parameters to be included in the HTTP request.

There is a daily limit of 100,000 records (which resets at 12 AM UTC) for videos and comments while, for the followers/following endpoint, the limit is set up to 2 million records (\url{https://developers.tiktok.com/doc/research-api-faq/}).

In this project, every call is parameterized to retrieve the maximum allowed data, typically 100 records. However, the APIs do not always provide the exact data requested, possibly due to a lack of content or other unknown issues.

\subsubsection*{Download Component}

A wrapper for the APIs has been realized for data gathering, which simply makes WebAPI calls and stores the results.
Almost every public endpoint provided has been totally covered by the script, specifically: users' followers, users' videos, videos' comments, following users, liked videos, and users' information.

In the first step, the script authenticates to TikTok's endpoint, gaining the token, which will be refreshed a few minutes before its 2-hour lifespan. Then it starts retrieving the data batch required, storing each response in a JSON file for later analysis.

For the specified number of videos, in this case 100 per month for each super-user (see second code block of section \ref{lst:query}), the script will download their metadata and store them, before concluding its job by retrieving super-users' followers.

\begin{lstlisting}[language=Python]
# @query {JSON} the video query as specified in the TikTok docs
# @nrVideo {int} the number of videos which we want to download
# @startDate {string} in Unix format
# @endDate {string} in Unix format -- NB: can't be greater than a month
# @filename {string} of JSON where data will be stored
def processVideo(query, nrVideo, nrComments, startDate, endDate, filename):
    ....

processVideo(videoQuery,100,200,'20240301','20240330','influencer-month')
\end{lstlisting}

\subsubsection*{Amount of Data Downloaded}

For each video, followers have been downloaded (100 per request) for up to 5 days, within 3-hour intervals, allowing for the retrieval of a theoretical number of followers equal to 4,000:

\[ (100 \text{ users} \times ((24 \text{h}/3 \text{h}) \times 5 = 40 \text{ requests})) = 4000 \]

However, such numbers are reached only if all new followers are distinct in every call, which is difficult to achieve within such a short time span.

Since TikTok's APIs return the user who has started following the influencer from the date (in Unix format) declared in the body of the request (called cursor), the problem of duplicated accounts arises.

To clarify: if \textit{JohnDoe} follows \textit{MrWhite} on 31/12/2023 at 10:00:00 and \textit{MrWhite} does not gain 100 new followers in the next 3 hours, \textit{JohnDoe} will also be included in the request at 31/12/2023 at 13:00:00.

To solve this problem, a Python script (\textit{DataCleaner.py}) was created, which keeps only the first occurrence (sorted by ascending date) of each username found in the total downloaded data.

\begin{lstlisting}[language=Python]
for i in range(0,len(total)-1):
for j in range(i+1, len(total)):
    if(total[i].get("influencer")==total[j].get("influencer")): ##check if the same influencer (we don't want to remove common followers)
        total[i]["followerList"] = [elem for elem in total[i].get("followerList") if elem not in total[j].get("followerList")]
\end{lstlisting}

Additionally, video metadata (such as views, likes, number of comments, etc) and super-users' public information (with a single call for each one) are stored for a later analysis. 

Ultimately, the total amount of data downloaded, divided among 10 super-users, is as follows:
\begin{itemize}
    \item 35,798 distinct followers;
    \item 182 videos.
\end{itemize}